{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull in the dataset\n",
    "df_raw = pd.read_csv('..//Datasets//creditcard.csv')\n",
    "\n",
    "# Show the shape and the head\n",
    "print(df_raw.shape)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <th>Amount</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>8.834962e+01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>25691.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th>Class</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.727486e-03</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th>Time</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.481386e+04</td>\n",
       "      <td>47488.145955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54201.500000</td>\n",
       "      <td>84692.000000</td>\n",
       "      <td>139320.500000</td>\n",
       "      <td>172792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <th>V1</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>1.958696</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-0.920373</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>1.315642</td>\n",
       "      <td>2.454930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <th>V10</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.768627e-15</td>\n",
       "      <td>1.088850</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>-0.535426</td>\n",
       "      <td>-0.092917</td>\n",
       "      <td>0.453923</td>\n",
       "      <td>23.745136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <th>V11</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.170318e-16</td>\n",
       "      <td>1.020713</td>\n",
       "      <td>-4.797473</td>\n",
       "      <td>-0.762494</td>\n",
       "      <td>-0.032757</td>\n",
       "      <td>0.739593</td>\n",
       "      <td>12.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <th>V12</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.810658e-15</td>\n",
       "      <td>0.999201</td>\n",
       "      <td>-18.683715</td>\n",
       "      <td>-0.405571</td>\n",
       "      <td>0.140033</td>\n",
       "      <td>0.618238</td>\n",
       "      <td>7.848392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count          mean           std        min           25%  \\\n",
       "Amount Amount  284807.0  8.834962e+01    250.120109   0.000000      5.600000   \n",
       "Class  Class   284807.0  1.727486e-03      0.041527   0.000000      0.000000   \n",
       "Time   Time    284807.0  9.481386e+04  47488.145955   0.000000  54201.500000   \n",
       "V1     V1      284807.0  3.919560e-15      1.958696 -56.407510     -0.920373   \n",
       "V10    V10     284807.0  1.768627e-15      1.088850 -24.588262     -0.535426   \n",
       "V11    V11     284807.0  9.170318e-16      1.020713  -4.797473     -0.762494   \n",
       "V12    V12     284807.0 -1.810658e-15      0.999201 -18.683715     -0.405571   \n",
       "\n",
       "                        50%            75%            max  \n",
       "Amount Amount     22.000000      77.165000   25691.160000  \n",
       "Class  Class       0.000000       0.000000       1.000000  \n",
       "Time   Time    84692.000000  139320.500000  172792.000000  \n",
       "V1     V1          0.018109       1.315642       2.454930  \n",
       "V10    V10        -0.092917       0.453923      23.745136  \n",
       "V11    V11        -0.032757       0.739593      12.018913  \n",
       "V12    V12         0.140033       0.618238       7.848392  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the first few rows, it appears that the data is already normalized. Let's check.\n",
    "df_raw.groupby(df_raw.columns, axis=1).describe().head(n=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that all of the PCA Columns average out to zero, and have small standard deviations. Since the Amount and Time data are much larger than the other columns, we will have to scale them as well. Even when the \"V\" columns have a large range, their IQR is still approximately -1 <-> 1, which means that there are outliers present. I will preserve the outliers from the Amount and Time columns with sklearn's standard scaler method. The Normalize method would shrink everything to be explicitly between -1 and 1, and we don't want that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for missing values: \n",
      "There are 0 missing values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83225</th>\n",
       "      <td>-0.738270</td>\n",
       "      <td>-1.648591</td>\n",
       "      <td>1.228130</td>\n",
       "      <td>1.370169</td>\n",
       "      <td>-1.735542</td>\n",
       "      <td>-0.029455</td>\n",
       "      <td>-0.484129</td>\n",
       "      <td>0.918645</td>\n",
       "      <td>-0.438750</td>\n",
       "      <td>0.982144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384201</td>\n",
       "      <td>-0.218076</td>\n",
       "      <td>-0.203458</td>\n",
       "      <td>-0.213015</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>-0.304481</td>\n",
       "      <td>0.632063</td>\n",
       "      <td>-0.262968</td>\n",
       "      <td>-0.099863</td>\n",
       "      <td>-0.196016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52800</th>\n",
       "      <td>-1.035079</td>\n",
       "      <td>-0.234775</td>\n",
       "      <td>-0.493269</td>\n",
       "      <td>1.236728</td>\n",
       "      <td>-2.338793</td>\n",
       "      <td>-1.176733</td>\n",
       "      <td>0.885733</td>\n",
       "      <td>-1.960981</td>\n",
       "      <td>-2.363412</td>\n",
       "      <td>-2.694774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364679</td>\n",
       "      <td>-1.495358</td>\n",
       "      <td>-0.083066</td>\n",
       "      <td>0.074612</td>\n",
       "      <td>-0.347329</td>\n",
       "      <td>0.541900</td>\n",
       "      <td>-0.433294</td>\n",
       "      <td>0.089293</td>\n",
       "      <td>0.212029</td>\n",
       "      <td>-0.107223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21293</th>\n",
       "      <td>-1.331382</td>\n",
       "      <td>1.134626</td>\n",
       "      <td>-0.774460</td>\n",
       "      <td>-0.163390</td>\n",
       "      <td>-0.533358</td>\n",
       "      <td>-0.604555</td>\n",
       "      <td>-0.244482</td>\n",
       "      <td>-0.212682</td>\n",
       "      <td>0.040782</td>\n",
       "      <td>-1.136627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396476</td>\n",
       "      <td>-0.684454</td>\n",
       "      <td>-1.855269</td>\n",
       "      <td>0.171997</td>\n",
       "      <td>-0.387783</td>\n",
       "      <td>-0.062985</td>\n",
       "      <td>0.245118</td>\n",
       "      <td>-0.061178</td>\n",
       "      <td>0.012180</td>\n",
       "      <td>0.086696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133600</th>\n",
       "      <td>-0.302019</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>1.017753</td>\n",
       "      <td>1.033117</td>\n",
       "      <td>1.384376</td>\n",
       "      <td>0.223233</td>\n",
       "      <td>-0.310845</td>\n",
       "      <td>0.597287</td>\n",
       "      <td>-0.127658</td>\n",
       "      <td>-0.701533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.097023</td>\n",
       "      <td>0.369957</td>\n",
       "      <td>-0.219266</td>\n",
       "      <td>-0.124941</td>\n",
       "      <td>-0.049749</td>\n",
       "      <td>-0.112946</td>\n",
       "      <td>0.114440</td>\n",
       "      <td>0.066101</td>\n",
       "      <td>-0.306794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38225</th>\n",
       "      <td>-1.168730</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>0.610092</td>\n",
       "      <td>-0.114437</td>\n",
       "      <td>0.256565</td>\n",
       "      <td>2.290752</td>\n",
       "      <td>4.008475</td>\n",
       "      <td>-0.123530</td>\n",
       "      <td>1.038374</td>\n",
       "      <td>-0.075846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292972</td>\n",
       "      <td>-0.019733</td>\n",
       "      <td>0.165463</td>\n",
       "      <td>-0.080978</td>\n",
       "      <td>1.020656</td>\n",
       "      <td>-0.300730</td>\n",
       "      <td>-0.269595</td>\n",
       "      <td>0.481769</td>\n",
       "      <td>0.254114</td>\n",
       "      <td>-0.260020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "83225  -0.738270 -1.648591  1.228130  1.370169 -1.735542 -0.029455 -0.484129   \n",
       "52800  -1.035079 -0.234775 -0.493269  1.236728 -2.338793 -1.176733  0.885733   \n",
       "21293  -1.331382  1.134626 -0.774460 -0.163390 -0.533358 -0.604555 -0.244482   \n",
       "133600 -0.302019  0.069514  1.017753  1.033117  1.384376  0.223233 -0.310845   \n",
       "38225  -1.168730 -0.199441  0.610092 -0.114437  0.256565  2.290752  4.008475   \n",
       "\n",
       "              V7        V8        V9    ...          V20       V21       V22  \\\n",
       "83225   0.918645 -0.438750  0.982144    ...     0.384201 -0.218076 -0.203458   \n",
       "52800  -1.960981 -2.363412 -2.694774    ...     0.364679 -1.495358 -0.083066   \n",
       "21293  -0.212682  0.040782 -1.136627    ...    -0.396476 -0.684454 -1.855269   \n",
       "133600  0.597287 -0.127658 -0.701533    ...     0.148760  0.097023  0.369957   \n",
       "38225  -0.123530  1.038374 -0.075846    ...     0.292972 -0.019733  0.165463   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \n",
       "83225  -0.213015  0.011372 -0.304481  0.632063 -0.262968 -0.099863 -0.196016  \n",
       "52800   0.074612 -0.347329  0.541900 -0.433294  0.089293  0.212029 -0.107223  \n",
       "21293   0.171997 -0.387783 -0.062985  0.245118 -0.061178  0.012180  0.086696  \n",
       "133600 -0.219266 -0.124941 -0.049749 -0.112946  0.114440  0.066101 -0.306794  \n",
       "38225  -0.080978  1.020656 -0.300730 -0.269595  0.481769  0.254114 -0.260020  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Check for missing values: \\nThere are {0:} missing values'.format(df_raw.isnull().sum().max()))\n",
    "\n",
    "# Split our training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_raw.drop('Class', 1).copy(),\n",
    "                                                    df_raw.loc[:, 'Class'].copy(),\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Create scaler object using the X_train variable\n",
    "scaler = StandardScaler().fit(X_train.loc[:, ('Amount', 'Time')])\n",
    "\n",
    "# Standardize X_train and X_test values\n",
    "standardized_X = scaler.transform(X_train.loc[:, ('Amount', 'Time')])\n",
    "standardized_X_test = scaler.transform(X_test.loc[:, ('Amount', 'Time')])\n",
    "\n",
    "# Change the X_train and X_test to our new standardized values\n",
    "X_train.loc[:, ('Amount', 'Time')], X_test.loc[:, ('Amount', 'Time')] = standardized_X, standardized_X_test\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's kind of nice, our data has already been cleaned of missing values. Is that a result of PCA? Not necessarily in this case, because whoever made the data may have imputed, but I was wondering if PCA would fill a missing value since the data is being transformed onto a different vector space. So many questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's try an SVC with l2 regularization\n",
    "clf = LinearSVC(class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "target_names = ['Non-Fraudulent', 'Fraudulent']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important thing to note in this application is that banks want to be absolutely sure that they do not let fraudsters go unnoticed. They will get fined by the government out the wazoo, so they would rather report a ton of false positives because then they can be sure that they don't get fined. It mostly serves to help narrow down the search for fraudsters, and not necessarily call each of them out individually. I learned this from my mentor.\n",
    "\n",
    "What this means for us, is that we need to have a very high recall. A recall of 1 is ideal, so let's try to force that so our branch doesn't get fined.\n",
    "\n",
    "For my memory/understanding, 'recall' corresponds to doctor's being 'really' careful to not miss cancer patients. An example of high 'precision' is a very 'precise' advertising campaign. You don't want to send ads to people that won't look at them (kinda like a false positive), so you only send ads to people that you think are more likely to respond to them. In this way you get most bang for your advertising buck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And let's try an SVC with L1 regularization. I doubt this will be any better, because PCA has reduced data\n",
    "# to only the important eigan features, so zeroing out feature coefficients wouldn't help that much. \n",
    "clf = LinearSVC(class_weight='balanced', loss='hinge')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "target_names = ['Non-Fraudulent', 'Fraudulent']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the first time I've been wrong, and it won't be the last! There is a way to increase our recall in the initialization of our Linear SVC, so let's learn/do that real quick and see if it gets us to 100% recall. To converge on a class weight more quickly, I will use a subset of the data. I will show that the class imbalance is similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 1 # How small of increments will we need? I don't know. Let's use 100 for now, by 5\n",
    "n_steps = 10\n",
    "start = .05\n",
    "stop = 1\n",
    "n_subset_examples = 20000\n",
    "\n",
    "# Let's use the subset and ensure our class imbalance is roughly the same using a t-test\n",
    "print(ttest_ind(y_train, y_train.iloc[0:n_subset_examples]), '\\n')\n",
    "print('Original Imbalance: \\n{:.3f}%\\n'.format(100 * y_train.value_counts()[1] / y_train.value_counts()[0]))\n",
    "print('Subset Imbalance: \\n{:.3f}%\\n'.format(100 * y_train.iloc[0:n_subset_examples].value_counts()[1] / \n",
    "                                           y_train.iloc[0:n_subset_examples].value_counts()[0]))\n",
    "\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "weights = []\n",
    "\n",
    "for i in np.arange(start, stop, resolution/n_steps):\n",
    "    # Initialize the LinearSVC with different class weights\n",
    "    clf = LinearSVC(class_weight={0:i, 1:1-i}, loss='hinge')\n",
    "    clf.fit(X_train.iloc[:n_subset_examples], y_train.iloc[:n_subset_examples])\n",
    "    y_pred = clf.predict(X_test.iloc[:n_subset_examples])\n",
    "    target_names = ['Non-Fraudulent', 'Fraudulent']\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_test.iloc[:n_subset_examples], y_pred, average='binary')\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1_score)\n",
    "    weights.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Plot all three scores on the same graph\n",
    "plt.plot(weights, precision_scores, label='Precision Score')\n",
    "plt.plot(weights, recall_scores, label='Recall Score')\n",
    "plt.plot(weights, f1_scores, label='F1 Score')\n",
    "\n",
    "# Make it look nice\n",
    "plt.xlabel('Non-Fraudulent Weight')\n",
    "plt.ylabel('Score')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that when the non-fraudulent class is weighted lower (and the fraudulent class weighted higher) that all three metrics are improved and seem to level out as the weight approaches zero. Let's see if a different classifier can get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "precision_knn = []\n",
    "recall_knn = []\n",
    "f1_knn = []\n",
    "n_neighbors_range = 9\n",
    "for i in np.arange(1, n_neighbors_range):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i, n_jobs=3)\n",
    "    knn.fit(X_train.iloc[:n_subset_examples, :], y_train.iloc[:n_subset_examples])\n",
    "    y_pred_knn = knn.predict(X_test.iloc[:n_subset_examples, :])\n",
    "    result = precision_recall_fscore_support(y_test.iloc[:n_subset_examples], y_pred_knn, average='binary')\n",
    "    precision_knn.append(result[0])\n",
    "    recall_knn.append(result[1])\n",
    "    f1_knn.append(result[2])\n",
    "    print('Result for k={}: \\n'.format(i), result)\n",
    "n_neighbors = np.arange(1, n_neighbors_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(n_neighbors, recall_knn, label='Recall')\n",
    "plt.plot(n_neighbors, precision_knn, label='Precision')\n",
    "plt.plot(n_neighbors, f1_knn, label='F1')\n",
    "plt.legend()\n",
    "plt.xlim([0, 10])\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, I would still like to get a higher recall score. Let's try another SVC but this time we will use a non-linear kernel. Failing high recall with that, we will try an ensemble method like random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# We will use a class weight of 0.15, because that seemed to work well in our LinearSVC\n",
    "rbf_clf = SVC(class_weight={0:0.15, 1:0.85}, kernel='rbf')\n",
    "rbf_clf.fit(X_train, y_train)\n",
    "y_pred_rbf = rbf_clf.predict(X_test)\n",
    "result = precision_recall_fscore_support(y_test, y_pred_rbf, average='binary')\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
