{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull in the dataset\n",
    "df_raw = pd.read_csv('..//Datasets//creditcard.csv')\n",
    "\n",
    "# Show the shape and the head\n",
    "print(df_raw.shape)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <th>Amount</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>8.834962e+01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>25691.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th>Class</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.727486e-03</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th>Time</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.481386e+04</td>\n",
       "      <td>47488.145955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54201.500000</td>\n",
       "      <td>84692.000000</td>\n",
       "      <td>139320.500000</td>\n",
       "      <td>172792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <th>V1</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>1.958696</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-0.920373</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>1.315642</td>\n",
       "      <td>2.454930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <th>V10</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.768627e-15</td>\n",
       "      <td>1.088850</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>-0.535426</td>\n",
       "      <td>-0.092917</td>\n",
       "      <td>0.453923</td>\n",
       "      <td>23.745136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <th>V11</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.170318e-16</td>\n",
       "      <td>1.020713</td>\n",
       "      <td>-4.797473</td>\n",
       "      <td>-0.762494</td>\n",
       "      <td>-0.032757</td>\n",
       "      <td>0.739593</td>\n",
       "      <td>12.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <th>V12</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.810658e-15</td>\n",
       "      <td>0.999201</td>\n",
       "      <td>-18.683715</td>\n",
       "      <td>-0.405571</td>\n",
       "      <td>0.140033</td>\n",
       "      <td>0.618238</td>\n",
       "      <td>7.848392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count          mean           std        min           25%  \\\n",
       "Amount Amount  284807.0  8.834962e+01    250.120109   0.000000      5.600000   \n",
       "Class  Class   284807.0  1.727486e-03      0.041527   0.000000      0.000000   \n",
       "Time   Time    284807.0  9.481386e+04  47488.145955   0.000000  54201.500000   \n",
       "V1     V1      284807.0  3.919560e-15      1.958696 -56.407510     -0.920373   \n",
       "V10    V10     284807.0  1.768627e-15      1.088850 -24.588262     -0.535426   \n",
       "V11    V11     284807.0  9.170318e-16      1.020713  -4.797473     -0.762494   \n",
       "V12    V12     284807.0 -1.810658e-15      0.999201 -18.683715     -0.405571   \n",
       "\n",
       "                        50%            75%            max  \n",
       "Amount Amount     22.000000      77.165000   25691.160000  \n",
       "Class  Class       0.000000       0.000000       1.000000  \n",
       "Time   Time    84692.000000  139320.500000  172792.000000  \n",
       "V1     V1          0.018109       1.315642       2.454930  \n",
       "V10    V10        -0.092917       0.453923      23.745136  \n",
       "V11    V11        -0.032757       0.739593      12.018913  \n",
       "V12    V12         0.140033       0.618238       7.848392  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the first few rows, it appears that the data is already normalized. Let's check.\n",
    "df_raw.groupby(df_raw.columns, axis=1).describe().head(n=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that all of the PCA Columns average out to zero, and have small standard deviations. Since the Amount and Time data are much larger than the other columns, we will have to scale them as well. Even when the \"V\" columns have a large range, their IQR is still approximately -1 <-> 1, which means that there are outliers present. I will preserve the outliers from the Amount and Time columns with sklearn's standard scaler method. The Normalize method would shrink everything to be explicitly between -1 and 1, and we don't want that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for missing values: \n",
      "There are 0 missing values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83225</th>\n",
       "      <td>-0.738270</td>\n",
       "      <td>-1.648591</td>\n",
       "      <td>1.228130</td>\n",
       "      <td>1.370169</td>\n",
       "      <td>-1.735542</td>\n",
       "      <td>-0.029455</td>\n",
       "      <td>-0.484129</td>\n",
       "      <td>0.918645</td>\n",
       "      <td>-0.438750</td>\n",
       "      <td>0.982144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384201</td>\n",
       "      <td>-0.218076</td>\n",
       "      <td>-0.203458</td>\n",
       "      <td>-0.213015</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>-0.304481</td>\n",
       "      <td>0.632063</td>\n",
       "      <td>-0.262968</td>\n",
       "      <td>-0.099863</td>\n",
       "      <td>-0.196016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52800</th>\n",
       "      <td>-1.035079</td>\n",
       "      <td>-0.234775</td>\n",
       "      <td>-0.493269</td>\n",
       "      <td>1.236728</td>\n",
       "      <td>-2.338793</td>\n",
       "      <td>-1.176733</td>\n",
       "      <td>0.885733</td>\n",
       "      <td>-1.960981</td>\n",
       "      <td>-2.363412</td>\n",
       "      <td>-2.694774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364679</td>\n",
       "      <td>-1.495358</td>\n",
       "      <td>-0.083066</td>\n",
       "      <td>0.074612</td>\n",
       "      <td>-0.347329</td>\n",
       "      <td>0.541900</td>\n",
       "      <td>-0.433294</td>\n",
       "      <td>0.089293</td>\n",
       "      <td>0.212029</td>\n",
       "      <td>-0.107223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21293</th>\n",
       "      <td>-1.331382</td>\n",
       "      <td>1.134626</td>\n",
       "      <td>-0.774460</td>\n",
       "      <td>-0.163390</td>\n",
       "      <td>-0.533358</td>\n",
       "      <td>-0.604555</td>\n",
       "      <td>-0.244482</td>\n",
       "      <td>-0.212682</td>\n",
       "      <td>0.040782</td>\n",
       "      <td>-1.136627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396476</td>\n",
       "      <td>-0.684454</td>\n",
       "      <td>-1.855269</td>\n",
       "      <td>0.171997</td>\n",
       "      <td>-0.387783</td>\n",
       "      <td>-0.062985</td>\n",
       "      <td>0.245118</td>\n",
       "      <td>-0.061178</td>\n",
       "      <td>0.012180</td>\n",
       "      <td>0.086696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133600</th>\n",
       "      <td>-0.302019</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>1.017753</td>\n",
       "      <td>1.033117</td>\n",
       "      <td>1.384376</td>\n",
       "      <td>0.223233</td>\n",
       "      <td>-0.310845</td>\n",
       "      <td>0.597287</td>\n",
       "      <td>-0.127658</td>\n",
       "      <td>-0.701533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.097023</td>\n",
       "      <td>0.369957</td>\n",
       "      <td>-0.219266</td>\n",
       "      <td>-0.124941</td>\n",
       "      <td>-0.049749</td>\n",
       "      <td>-0.112946</td>\n",
       "      <td>0.114440</td>\n",
       "      <td>0.066101</td>\n",
       "      <td>-0.306794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38225</th>\n",
       "      <td>-1.168730</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>0.610092</td>\n",
       "      <td>-0.114437</td>\n",
       "      <td>0.256565</td>\n",
       "      <td>2.290752</td>\n",
       "      <td>4.008475</td>\n",
       "      <td>-0.123530</td>\n",
       "      <td>1.038374</td>\n",
       "      <td>-0.075846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292972</td>\n",
       "      <td>-0.019733</td>\n",
       "      <td>0.165463</td>\n",
       "      <td>-0.080978</td>\n",
       "      <td>1.020656</td>\n",
       "      <td>-0.300730</td>\n",
       "      <td>-0.269595</td>\n",
       "      <td>0.481769</td>\n",
       "      <td>0.254114</td>\n",
       "      <td>-0.260020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "83225  -0.738270 -1.648591  1.228130  1.370169 -1.735542 -0.029455 -0.484129   \n",
       "52800  -1.035079 -0.234775 -0.493269  1.236728 -2.338793 -1.176733  0.885733   \n",
       "21293  -1.331382  1.134626 -0.774460 -0.163390 -0.533358 -0.604555 -0.244482   \n",
       "133600 -0.302019  0.069514  1.017753  1.033117  1.384376  0.223233 -0.310845   \n",
       "38225  -1.168730 -0.199441  0.610092 -0.114437  0.256565  2.290752  4.008475   \n",
       "\n",
       "              V7        V8        V9    ...          V20       V21       V22  \\\n",
       "83225   0.918645 -0.438750  0.982144    ...     0.384201 -0.218076 -0.203458   \n",
       "52800  -1.960981 -2.363412 -2.694774    ...     0.364679 -1.495358 -0.083066   \n",
       "21293  -0.212682  0.040782 -1.136627    ...    -0.396476 -0.684454 -1.855269   \n",
       "133600  0.597287 -0.127658 -0.701533    ...     0.148760  0.097023  0.369957   \n",
       "38225  -0.123530  1.038374 -0.075846    ...     0.292972 -0.019733  0.165463   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \n",
       "83225  -0.213015  0.011372 -0.304481  0.632063 -0.262968 -0.099863 -0.196016  \n",
       "52800   0.074612 -0.347329  0.541900 -0.433294  0.089293  0.212029 -0.107223  \n",
       "21293   0.171997 -0.387783 -0.062985  0.245118 -0.061178  0.012180  0.086696  \n",
       "133600 -0.219266 -0.124941 -0.049749 -0.112946  0.114440  0.066101 -0.306794  \n",
       "38225  -0.080978  1.020656 -0.300730 -0.269595  0.481769  0.254114 -0.260020  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Check for missing values: \\nThere are {0:} missing values'.format(df_raw.isnull().sum().max()))\n",
    "\n",
    "# Split our training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_raw.drop('Class', 1).copy(),\n",
    "                                                    df_raw.loc[:, 'Class'].copy(),\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Create scaler object using the X_train variable\n",
    "scaler = StandardScaler().fit(X_train.loc[:, ('Amount', 'Time')])\n",
    "\n",
    "# Standardize X_train and X_test values\n",
    "standardized_X = scaler.transform(X_train.loc[:, ('Amount', 'Time')])\n",
    "standardized_X_test = scaler.transform(X_test.loc[:, ('Amount', 'Time')])\n",
    "\n",
    "# Change the X_train and X_test to our new standardized values\n",
    "X_train.loc[:, ('Amount', 'Time')], X_test.loc[:, ('Amount', 'Time')] = standardized_X, standardized_X_test\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's kind of nice, our data has already been cleaned of missing values. Is that a result of PCA? Not necessarily in this case, because whoever made the data may have imputed, but I was wondering if PCA would fill a missing value since the data is being transformed onto a different vector space. So many questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "Non-Fraudulent       1.00      1.00      1.00     71089\n",
      "    Fraudulent       0.70      0.72      0.71       113\n",
      "\n",
      "   avg / total       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First, let's try an SVC with l2 regularization\n",
    "clf = LinearSVC(class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "target_names = ['Non-Fraudulent', 'Fraudulent']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important thing to note in this application is that banks want to be absolutely sure that they do not let fraudsters go unnoticed. They will get fined by the government out the wazoo, so they would rather report a ton of false positives because then they can be sure that they don't get fined. It mostly serves to help narrow down the search for fraudsters, and not necessarily call each of them out individually. I learned this from my mentor.\n",
    "\n",
    "What this means for us, is that we need to have a very high recall. A recall of 1 is ideal, so let's try to force that so our branch doesn't get fined.\n",
    "\n",
    "For my memory/understanding, 'recall' corresponds to doctor's being 'really' careful to not miss cancer patients. An example of high 'precision' is a very 'precise' advertising campaign. You don't want to send ads to people that won't look at them (kinda like a false positive), so you only send ads to people that you think are more likely to respond to them. In this way you get most bang for your advertising buck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "Non-Fraudulent       1.00      1.00      1.00     71089\n",
      "    Fraudulent       0.56      0.81      0.66       113\n",
      "\n",
      "   avg / total       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And let's try an SVC with L1 regularization. I doubt this will be any better, because PCA has reduced data\n",
    "# to only the important eigan features, so zeroing out feature coefficients wouldn't help that much. \n",
    "clf = LinearSVC(class_weight='balanced', loss='hinge')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "target_names = ['Non-Fraudulent', 'Fraudulent']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the first time I've been wrong, and it won't be the last! There is a way to increase our recall in the initialization of our Linear SVC, so let's learn/do that real quick and see if it gets us to 100% recall. To converge on a class weight more quickly, I will use a subset of the data. I will show that the class imbalance is similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.4006225908610417, pvalue=0.6886983770343691) \n",
      "\n",
      "Original Imbalance: \n",
      "0.178%\n",
      "\n",
      "Subset Imbalance: \n",
      "0.165%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resolution = 1 # How small of increments will we need? I don't know. Let's use 100 for now, by 5\n",
    "n_steps = 10\n",
    "start = .05\n",
    "stop = 1\n",
    "n_subset_examples = 20000\n",
    "\n",
    "# Let's use the subset and ensure our class imbalance is roughly the same using a t-test\n",
    "print(ttest_ind(y_train, y_train.iloc[0:n_subset_examples]), '\\n')\n",
    "print('Original Imbalance: \\n{:.3f}%\\n'.format(100 * y_train.value_counts()[1] / y_train.value_counts()[0]))\n",
    "print('Subset Imbalance: \\n{:.3f}%\\n'.format(100 * y_train.iloc[0:n_subset_examples].value_counts()[1] / \n",
    "                                           y_train.iloc[0:n_subset_examples].value_counts()[0]))\n",
    "\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "weights = []\n",
    "\n",
    "for i in np.arange(start, stop, resolution/n_steps):\n",
    "    # Initialize the LinearSVC with different class weights\n",
    "    clf = LinearSVC(class_weight={0:i, 1:1-i}, loss='hinge')\n",
    "    clf.fit(X_train.iloc[:n_subset_examples], y_train.iloc[:n_subset_examples])\n",
    "    y_pred = clf.predict(X_test.iloc[:n_subset_examples])\n",
    "    target_names = ['Non-Fraudulent', 'Fraudulent']\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_test.iloc[:n_subset_examples], y_pred, average='binary')\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1_score)\n",
    "    weights.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAJRCAYAAAAeWCASAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xd8leXh/vHPnT0ggSQgGyIbEsIIS0GQjQoUKkVUFKulimjFr1pX1V9dVakVW6rgwlWr1iKjoixRUQHDJswwlJCwEgiB7OT+/XFCBEUIISfPc8j1fr14NefkyTlXoMSL+7mHsdYiIiIiIu7i53QAEREREfk5lTQRERERF1JJExEREXEhlTQRERERF1JJExEREXEhlTQRERERF/JaSTPGvG6MOWCM2fgLnzfGmBeNMSnGmPXGmM7eyiIiIiLia7w5kjYTGHKGzw8FWpb+mgC85MUsIiIiIj7FayXNWvslkHmGS0YAb1mP5UAtY0x9b+URERER8SVOzklrCOw56XFq6XMiIiIi1V6Ag+9tTvPcac+oMsZMwHNLlPDw8C5t2rTxZi4RERGRSrFq1apD1to6FflaJ0taKtD4pMeNgLTTXWitnQHMAEhMTLRJSUneTyciIiJynowx31f0a5283TkHuKF0lWcPIMtam+5gHhERERHX8NpImjHmPaAvEGOMSQUeBQIBrLUvA58AVwApQA5wk7eyiIiIiPgar5U0a+3Ys3zeArd76/1FREREfJmTc9JERETkJIWFhaSmppKXl+d0FDlHISEhNGrUiMDAwEp7TZU0ERERl0hNTaVmzZo0a9YMY063CYK4kbWWjIwMUlNTiY2NrbTX1dmdIiIiLpGXl0d0dLQKmo8xxhAdHV3pI6AqaSIiIi6iguabvPHnppImIiIiZfz9/enYsSNxcXGMHj2anJyc837NpKQk7rzzzl/8fFpaGldfffV5vw/AvHnz6NSpEwkJCbRr147p06dXyus6wXgWWfoObWYrIiIXqs2bN9O2bVtHM9SoUYNjx44BcN1119GlSxfuvvvuss9ba7HW4ufnvnGewsJCmjZtysqVK2nUqBH5+fns3r2b1q1bV/g1z+X7Pd2fnzFmlbU2sSLv7b7fYREREXGF3r17k5KSwu7du2nbti0TJ06kc+fO7NmzhwULFtCzZ086d+7M6NGjy4rdd999xyWXXEJCQgLdunUjOzubpUuXctVVVwHwxRdf0LFjRzp27EinTp3Izs5m9+7dxMXFAZ55eTfddBPx8fF06tSJzz//HICZM2cyatQohgwZQsuWLbnvvvt+ljc7O5uioiKio6MBCA4OLito+/fvZ+TIkSQkJJCQkMA333wDwPPPP09cXBxxcXG88MILAOf0/XqTSpqIiIj8TFFREfPnzyc+Ph6ArVu3csMNN7BmzRrCw8N54oknWLRoEatXryYxMZHnn3+egoICxowZw9SpU1m3bh2LFi0iNDT0lNedMmUK06ZNY+3atXz11Vc/+/y0adMA2LBhA++99x433nhj2YT8tWvX8v7777Nhwwbef/999uzZc8rXRkVFMXz4cJo2bcrYsWN59913KSkpAeDOO++kT58+rFu3jtWrV9O+fXtWrVrFG2+8wYoVK1i+fDmvvPIKa9asKff3623agkNERMSF/t/cZDalHa3U12zXIIJHh7U/4zW5ubl07NgR8Iyk3XzzzaSlpdG0aVN69OgBwPLly9m0aROXXnopAAUFBfTs2ZOtW7dSv359unbtCkBERMTPXv/SSy/l7rvv5rrrrmPUqFE0atTolM8vW7aMO+64A4A2bdrQtGlTtm3bBkD//v2JjIz0fC/t2vH999/TuHHjU77+1VdfZcOGDSxatIgpU6awcOFCZs6cyZIlS3jrrbcAz7y7yMhIli1bxsiRIwkPDwdg1KhRfPXVV2VF72zfr7eppImIiEiZ0NBQ1q5d+7PnTxQZ8MzTGjhwIO+9994p16xfv/6sqxzvv/9+rrzySj755BN69OjBokWLCAkJOeW1f0lwcHDZx/7+/hQVFZ32uvj4eOLj4xk3bhyxsbHMnDnztNed6b3K8/16m0qaiIiIC51txMtJPXr04PbbbyclJYUWLVqQk5NDamoqbdq0IS0tje+++46uXbuSnZ39s9uZO3bsKCtR3377LVu2bCkbuQO47LLLePfdd+nXrx/btm3jhx9+oHXr1qxevfqsuY4dO0ZSUhJ9+/YFPLdHmzZtCnhG4V566SXuuusuiouLOX78OJdddhnjx4/n/vvvx1rLrFmzePvtt8v9/bZq1eo8fhfPTnPSRERE5JzUqVOHmTNnMnbsWDp06ECPHj3YsmULQUFBvP/++9xxxx0kJCQwcODAn23w+sILLxAXF0dCQgKhoaEMHTr0lM9PnDiR4uJi4uPjGTNmDDNnzjxlBO1MrLU8++yztG7dmo4dO/Loo4+WjaJNnTqVzz//nPj4eLp06UJycjKdO3dm/PjxdOvWje7du3PLLbfQqVOncn+/3qYtOERERFzCDVtwSMVpCw4RERGRakAlTURERMSFVNJEREREXEglTURERMSFVNJEREREXEglTURERMSFVNJERESkjL+/Px07diQuLo5hw4Zx5MiRSn39mTNnMmnSJAAee+wxpkyZ8rNrtm7dSt++fenYsSNt27ZlwoQJlZrBV6ikiYiISJkTx0Jt3LiRqKiosgPPq9Kdd97J5MmTWbt2LZs3by47y/N8FBcXV0KyqqWSJiIiIqfVs2dP9u7dW/b4ueeeo2vXrnTo0IFHH3207Pm33nqLDh06kJCQwLhx4wCYO3cu3bt3p1OnTgwYMID9+/eX+33T09NPOXg9Pj4e8BSte+65h/j4eDp06MDf//53ABYvXkynTp2Ij4/nt7/9Lfn5+QA0a9aMP//5z/Tq1YsPP/yQHTt2MGTIELp06ULv3r2r5NSA86GzO0VERORniouLWbx4MTfffDMACxYsYPv27axcuRJrLcOHD+fLL78kOjqaJ598kq+//pqYmBgyMzMB6NWrF8uXL8cYw6uvvsqzzz7LX//613K99+TJk+nXrx+XXHIJgwYN4qabbqJWrVrMmDGDXbt2sWbNGgICAsjMzCQvL4/x48ezePFiWrVqxQ033FB2RidASEgIy5YtAzznd7788su0bNmSFStWMHHiRJYsWeKF373KoZImIiLiRvPvh30bKvc168XD0L+c8ZLc3Fw6duzI7t276dKlCwMHDgQ8JW3BggVlZ1seO3aM7du3s27dOq6++mpiYmIAiIqKAiA1NZUxY8aQnp5OQUEBsbGx5Y550003MXjwYD799FNmz57N9OnTWbduHYsWLeLWW28lICCg7L3WrVtHbGxs2WHnN954I9OmTSsraWPGjCnL+8033zB69Oiy9zkx4uZWut0pIiIiZU7MSfv+++8pKCgom5NmreWBBx5g7dq1rF27lpSUFG6++WastRhjfvY6d9xxB5MmTWLDhg1Mnz79Zwetn02DBg347W9/y+zZswkICGDjxo2nfa+znUEeHh4OQElJCbVq1SrLf2K+m5tpJE1ERMSNzjLi5W2RkZG8+OKLjBgxgttuu43Bgwfzpz/9ieuuu44aNWqwd+9eAgMD6d+/PyNHjmTy5MlER0eTmZlJVFQUWVlZNGzYEIA333zznN77008/pX///gQGBrJv3z4yMjJo2LAhgwYN4uWXX6Zv375ltzvbtGnD7t27SUlJoUWLFrz99tv06dPnZ68ZERFBbGwsH374IaNHj8Zay/r160lISKiU3y9v0EiaiIiInFanTp1ISEjg3//+N4MGDeLaa6+lZ8+exMfHc/XVV5OdnU379u156KGH6NOnDwkJCdx9992AZ3uN0aNH07t377JboeW1YMEC4uLiSEhIYPDgwTz33HPUq1ePW265hSZNmpQtUvjXv/5FSEgIb7zxBqNHjyY+Ph4/Pz9uvfXW077uu+++y2uvvUZCQgLt27dn9uzZ5/175E3mbMOEbpOYmGiTkpKcjiEiIlLpNm/eTNu2bZ2OIRV0uj8/Y8wqa21iRV5PI2kiIiIiLqSSJiIiIuJCKmkiIiIiLqSSJiIiIuJCKmkiIiIiLqSSJiIiIuJCKmkiIiJSxt/fn44dO5b92r17NxkZGVx++eXUqFGDSZMm/eLXzps3r2xvtXbt2jF9+vQqTH7h0YkDIiIiUubEsVAnO378OI8//jgbN25k48aNp/26wsJCJkyYwMqVK2nUqBH5+fns3r37vLJYa7HW4udXPceUqud3LSIiIuUWHh5Or169CAkJ+cVrsrOzKSoqIjo6GoDg4GBat24NwP79+xk5ciQJCQkkJCTwzTffAPD8888TFxdHXFwcL7zwAgC7d++mbdu2TJw4kc6dO7Nnzx4WLFhAz5496dy5M6NHj+bYsWNe/o7dQSVNREREyuTm5pbd6hw5cmS5vy4qKorhw4fTtGlTxo4dy7vvvktJSQkAd955J3369GHdunWsXr2a9u3bs2rVKt544w1WrFjB8uXLeeWVV1izZg0AW7du5YYbbmDNmjWEh4fzxBNPsGjRIlavXk1iYiLPP/+8V753t9HtThERERd6ZuUzbMncUqmv2SaqDX/s9sczXnO6253l9eqrr7JhwwYWLVrElClTWLhwITNnzmTJkiW89dZbgGfOW2RkJMuWLWPkyJGEh4cDMGrUKL766quyotejRw8Ali9fzqZNm7j00ksBKCgooGfPnhXK52tU0kRERKTSxMfHEx8fz7hx44iNjWXmzJmnve5MZ4efKG4nrhs4cCDvvfdeZUd1PZU0ERERFzrbiJfbHDt2jKSkJPr27QvA2rVradq0KQD9+/fnpZde4q677qK4uJjjx49z2WWXMX78eO6//36stcyaNYu33377Z6/bo0cPbr/9dlJSUmjRogU5OTmkpqbSqlWrqvz2HKGSJiIiImfVrFkzjh49SkFBAR9//DELFiygXbt2ZZ+31vLss8/y+9//ntDQUMLDw8tG0aZOncqECRN47bXX8Pf356WXXqJnz56MHz+ebt26AXDLLbfQqVOnn60IrVOnDjNnzmTs2LHk5+cD8MQTT1SLkmbONNzoRomJiTYpKcnpGCIiIpVu8+bNtG3b1ukYUkGn+/Mzxqyy1iZW5PW0ulNERETEhVTSRERERFxIJU1ERETEhVTSREREXMTX5oqLhzf+3FTSREREXCIkJISMjAwVNR9jrSUjI+OMx2ZVhLbgEBERcYlGjRqRmprKwYMHnY4i5ygkJIRGjRpV6muqpImIiLhEYGAgsbGxTscQl9DtThEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERGRauPw8QKnI5RbgNMBRERERLxp96HjzFufxtx16RzLL+Kr+y7Hz884HeusVNJERETkgrP3SC7/Ky1mG/ZmAdC1WW2u7d6EohJLkEqaiIiISNU4kJ3HJ+vTmbc+naTvDwPQoVEkD13Rlis71KdBrVCHE54blTQRERHxWYePF/Bp8j7mrktj+c4MSiy0qVeTewe35qoO9WkaHe50xApTSRMRERGfcjSvkIXJ+5m7Po1l2w9RVGK5OCacSf1aMqxDfVpeVNPpiJVCJU1ERERcL6egiMWbDzB3XRpLtx2koKiEhrVCuaX3xVzVoT7tG0RgjPvnmZ0LlbQzuPXtVWxMy3I6hlfVCgukXkQo9SNDqBcZQr2IkB8/jgwhLEj/FxEREWfkFxXzxdaDzF2fzqJN+8ktLKZuzWCu696EYQkN6NS41gVXzE6m/wKfQbsGEYQF+zsdw3ssZOYUkHo4h6TvMzmSU/izSyJCAqgfGVpW4OpFnlri6keEEhEacEH/JRERkapTWFzC1ymHmLsunQXJ+8jOLyIqPIhRnRsyLKEBXZtF4e8DKzMrg0raGdzZv6XTEapUbkEx+47mkZ6Vy/6jeaRn5bEvy/O/+4/msSn9KIeO5WPtqV8XGuhP/cgQLjppFO7Hx56CFx0e5BN70oiISNUrLrGs2JXB3HXpfLoxncM5hdQMCWBIXD2GJTTgkubRBPhXv/33VdKkTGiQP7Ex4cTG/PJKmIKiEg5k5/2sxO076vl4xa5M9h/No6jk1CYX6G+oW/OXS1z9yBDq1AwmsBr+JRQRqY5KSixr9hxm7rp0/rchnYPZ+YQF+TOw3UUM69CA3q1iCA64gO9mlYNKmpyToAA/GtUOo1HtsF+8pqTEcuh4/imjcD8WulyS046yaPN+8gpLTvk6Y6BOjeBT5sfViwz9yeMQQgKr919aERFfZa1l496jzFufxrz16ew9kktQgB/929Tlqg4N6NemLqFB+hl/gkqaVDo/P8+oWd2aIXRodPprrLVk5RaeMgrnKXK57Duaz65Dx/lmRwbZeUU/+9raYYEn3VotLXE/mS9XMyTQy9+liIiU17b92cxdl8bcdWnszsgh0N/Qu2Ud7hncigFtL9LP7F+gkiaOMMZQKyyIWmFBtK0f8YvXHc8vOk2J+/Hx+tQsMk5zWG54kD/1a4XSul5N2jeIIK5BJO0bRBBdI9ib35aIiJTadeg489alMXd9Gtv2H8PPwCXNY7itb3MGt69HrbAgpyO6nkqauFp4cADN69SgeZ0av3hNflExB47mnzQql0t6Vh57D+eyPvUI/1ufXnZt/cgQ2pcWtriGkcQ1jKBeRIhWp4qIVILUwzn8b306c9ensXHvUQC6NYvi8RHtGRJXnzo19Q/lc6GSJj4vOMCfxlFhNI46/Ty5rJxCktOzSN57lI1pWSSnHWXxlv1lq1SjwoNo3yCC9g08pS2uQSRNosK0GlVEpBxOnJc5d306q0rPy0xoXIuHr/Scl1k/0rfOy3QTY3+6n4LLJSYm2qSkJKdjiI/LKShic3o2yWlZbNzrKW7b9mdTWOz5+1AjOIB2DSLKbpXGNYykeZ3warkEXETkpzKPF/DpxtLzMndlYC20rR/BVR3qM6xDA5pE//LisurGGLPKWptYka/VSJpUS2FBAXRpWpsuTWuXPZdfVMz2/cdKi9tRktOyeG/lD2WrUIMD/GhTP4K4k0bdWl1UU6tNRaRaOJpXyILk/cxdl8bXKaXnZdYJ585+LRmWUJ8WdS+M8zLdRCNpImdQXGLZefAYyWlH2bg3q+x26YlVpwF+hhZ1axDX8Md5bm3rR1AjWP/+ERHfl1NQxKLNB5i3Lo2lWw9SUFxCo9qhDEtowLAODWhbv6bm9J7F+YykqaSJnCNrLXsycz0jbieNuh065lllagzERofT/kRxK12oUDtcK5lExP3yCov5YttB5q5LY/HmA+QWFnNRRDBXdWjAsIQGJDSKVDE7B7rdKVKFjDE0iQ6jSXQYQ+PrA57idiA7v+xW6ca9Waz+/jBz16WVfV3DWqGnLlBoGEndmsHV4oddUXEJR/OKyMot5EhOAUdyC8nK8XyclVvEkdwCz+PcwrJrcguKnY4tUi0dyS0kp6CY6PAgru7SiKs61KdrsygtpnKASppIJTDGcFGE56irfm0uKnv+8PECktOOlo66ef534eYfV5bG1Ag6dUuQBpE0jgp1bXHLKyzmSE4hR3ILOJLjKVRZP3l85KTnPIWr8LSbEp+sZnAAkWGBRIYGUisskDb1IggN8sedvwsiF7bw4AD6t61Lz4ur53mZbqKSJuJFtcOD6NUyhl4tY8qeO5ZfxOb0oyTv9RS3jXuzyibhAtQMCfjZliAX16mBfyX9K7akxJJ9YlSrtFydGMHKyvnp41MLWH5RyS++rr+foVZoIJFhgdQKDaROjWBa1q1ZVrx+/FxQ2TWRoYFEhAbqzFYRkdNQSROpYjWCA+jaLIquzaLKnssrLGbb/uyTFigc5Z3l35eVopBAP9rWP3VLkNiYcI4XFJF1YgSrtFwdySngaO6Jj39SwHILOZpbSMkZpqKGBfkTGfrjqNbFMTXKPj5RsmqVjnqVFbCwIMKD/F07Aigi4ou0cEDEpYqKS9hx8PiP89zSsticdpTs/DPfOgTP4oXI0B9HqyLDgqh10ohWRKinWJ14LrJ0lCsyNJDgAG0pIiJSWVy7cMAYMwSYCvgDr1pr//KTzzcB3gRqlV5zv7X2E29mEvEVAf5+tK5Xk9b1ajKqs+e5khLLD5k5bEzL4ofMnNK5XCcXsCAiQwOpGRKgSb4iIj7OayXNGOMPTAMGAqnAd8aYOdbaTSdd9jDwgbX2JWNMO+AToJm3Mon4Oj8/Q7OYcJrFhDsdRUREvMybs3W7ASnW2p3W2gLg38CIn1xjgYjSjyOBNERERETEq7c7GwJ7TnqcCnT/yTWPAQuMMXcA4cAAL+Y5Z/d/dT9bM7c6HcOr4mPiGd58OF0u6qJJ3yIiIi7izZJ2uv/i/3SVwlhgprX2r8aYnsDbxpg4a+0p6/yNMROACQBNmjTxStjTqR9en4Ligip7v6pWUFzAZ7s/Y1bKLBrWaMjw5sMZ1nwYjWs2djqaiIhItee11Z2lpesxa+3g0scPAFhrnz7pmmRgiLV2T+njnUAPa+2BX3pdre6sXDmFOSz+YTGzd8xmZfpKLJbOdTszosUIBjUdRI2gGk5HFBER8VmuPLvTGBMAbAP6A3uB74BrrbXJJ10zH3jfWjvTGNMWWAw0tGcIpZLmPfuO72PujrnM2TGH3Ud3E+IfQr8m/RjRfATd63fH309bM4iIiJwLV5Y0AGPMFcALeLbXeN1a+6Qx5s9AkrV2TumKzleAGnhuhd5nrV1wptdUSfM+ay3rD61nTsoc5u+eT3ZBNnXD6nLVxVcxovkILq51sdMRRUREfIJrS5o3qKRVrfzifJbuWcqcHXP4eu/XFNti4qLjGN5iOEObDaVWSC2nI4qIiLiWSppUiUO5h/jfzv8xZ8ccth3eRoBfAH0b9WV48+H0atSLQL9ApyOKiIi4ikqaVLktmVuYnTKbT3Z9QmZeJlEhUVwRewUjWoygTVQbp+OJiIi4gkqaOKawpJCv937NnB1zWLpnKYUlhbSq3YrhzYdz5cVXEhMa43REERERx6ikiStk5Wcxf9d85uyYw4ZDG/A3/lzS4BKGtxjO5Y0vJ9g/2OmIIiIiVUolTVxn55GdzNkxh7k753Ig5wA1g2oypNkQhjcfTkKdBJ1uICIi1YJKmrhWcUkxK/atYM6OOSz+fjF5xXk0i2jGsObDGHbxMOrXqO90RBEREa9RSROfcKzgGAu/X8jsHbNZtX8VBkO3et0Y3mI4A5oMICwwzOmIIiIilUolTXzOnuw9zNsxjzk75pB6LJXQgFAGNh3IiOYjSKyXiJ/xczqiiIjIeVNJE59lrWX1gdXM2TGHz3Z/xvHC4zQIb8BVzT2nGzSJaOJ0RBERkQpTSZMLQm5RLkt+WMKcHXP4Nu1bLJaOdToyvMVwBjcbTERQhNMRRUREzolKmlxw9h/fz7ydntuhO7N2EuwfzOWNL2d48+H0bNCTAL8ApyOKiIiclUqaXLCstSRnJDM7ZTbzd88nKz+LOqF1uPLiKxnefDgta7d0OqKIiMgvUkmTaqGguIAvU79k9o7ZLEtdRpEtom1UW0a0GMEVsVdQO6S20xFFREROoZLmLZ8/DZk7qua9HGGg9RBoPwp8bHPZjNyMstMNNmduJsAE0LtRb0Y0H8FljS4j0F+HvYuIiPNU0rzlgxth3/qqeS8nFByHY/uhcXcY8jQ07OJ0ogrZdngbc1LmMG/nPDLyMqgVXIuhsUMZ0WIE7aPbOx1PRESqMZU0qZiSYlj7Liz+Mxw/CAnXQv9HIMI3TwEoKinim7RvmLNjDp//8DkFJQX0bdyXP3b9I41qNnI6noiIVEMqaXJ+8o7CV1Ng+UvgFwi9J0PPSRAY6nSyCsvKz+LDbR8yY/0MSmwJt8Tfwk1xN+mQdxERqVIqaVI5MnfCgj/BlnkQ2QQG/Rna/crn5qudbN/xfTz73bMs/H4hTWo24YHuD9CrYS+nY4mISDVxPiVNZ+/Ij6IuhmvehRvnQkgEfDge3rgC0tY6nazC6oXX4/m+zzN9wHSMMdy26DYmfz6Z9GPpTkcTERE5I42kyemVFMPqt2DJE5CTAZ2ug36PQM2LnE5WYQXFBbyZ/CYz1s/AGMOEDhO4sd2NWgkqIiJeo9ud4j15WfDlc7D8ZQgIht7/Bz0mQmCI08kqLO1YGs+sfIYle5bQLKIZD3Z/kJ4NejodS0RELkAqaeJ9GTtgwcOw9ROo1RQGPQFth/n0fLUvU7/kLyv/wp7sPQxuNph7Eu+hXng9p2OJiMgFRCVNqs6Oz+GzB+HAJmjWGwY/BfU7OJ2qwvKL83l94+u8tuE1/IwftyXcxvXtrifQT7dARUTk/KmkSdUqLoLVM2HJk5B7GDrfAP0ehhp1nU5WYXuy9/DMymf4IvULmkc258HuD9KtfjenY4mIiI9TSRNn5B6GL56DldMhIBT63Avdb/XMXfNRS/cs5S8r/8LeY3sZGjuUexPvpU5YHadjiYiIj1JJE2cd2g6fPQTbP4PasZ75am2u9Nn5arlFuby24TVe3/g6Qf5BTEyYyLVtryXAL8DpaCIi4mO0T5o4K6YlXPcBXP+RZxTt/evgreGwP9npZBUSGhDKpE6T+HjEx3Ss25Hnkp7jN/N+w6r9q5yOJiIi1YhG0qRyFRdB0uuw9CnP9h1dxsPlD0F4jNPJKsRay5IflvDMd8+Qfjyd4c2HM7nLZGJCffP7ERGRqqXbneI+OZnwxTOw8hUIqgF97oNuEyAgyOlkFZJTmMMrG15hZvJMQvxDmNRpEmNaj9EtUBEROSOVNHGvg1s9W3akLIKo5jD4SWg1xGfnq+3K2sVTK55iefpy2kS14aHuD9GxbkenY4mIiEtpTpq4V53Wnrlq1/0HjB+8dw28PRIObHY6WYXERsYyY+AMpvRZplYzAAAgAElEQVSZQmZeJuPmj+NPX/+JzLxMp6OJiMgFRiNpUnWKC+G7V2Hp05B/DBJvgr4PQni008kqJKcwh5fXv8zbyW8TGhjKHzr9gatbXY2/n7/T0URExCV0u1N8y/EMT1FLeh2Ca0DfB6DrLeCjB53vOLKDp1Y8xcp9K2kX3Y6Huz9MfJ14p2OJiIgLqKSJbzqwGT59AHZ+DtEtPUdMtRrkdKoKsdYyf9d8piRN4VDuIUa1HMVdne+iVkgtp6OJiIiDNCdNfFPdtjBuFox9H2wJ/Gs0vPNrOLDF6WTnzBjDFRdfwZxfzWFcu3F8nPIxV318Ff/Z9h9KbInT8URExAdpJE3coagAVs6AL56FgmOe259974ewKKeTVci2w9t4cvmTrD6wmviYeB7q8RDto9s7HUtERKqYbnfKheP4Ifj8SVg1E0IiPQsLEm/yyflq1lrm7ZzHX5P+SmZeJr9p/Rvu6HQHkcGRTkdzPWstxwuPOx1DpFoK8g8iyN8397R0I5U0ufDs2wifPQC7voSY1jDkKWgxwOlUFXK04Cj/XPtP3tvyHpFBkUzuMpkRLUbgZzTb4IT9x/ezMWMjyYeS2XhoI8kZyRwtOOp0LJFqKTQglKd6PcWApr75M9dtVNLkwmQtbP3Ec3j74V3QcpBncUFMS6eTVciWzC08ufxJ1h5cS8c6HXmox0O0iWrjdKwql5Wf5SljGRvZeMjz62DuQQD8jT8ta7ekfXR7mkU0w/jopscivmzB7gVsOLSBB7s/yDVtrnE6js9TSZMLW1E+rHgZvngOinI9x0v1uQ9Cazud7JyV2BLm7JjD31b9jSP5R7im9TXc3ul2IoIinI7mFTmFOWzJ3FJWxjZmbGRP9p6yzzeLaEb7mPbERccRFxNHm6g2hASEOJhYRHKLcrnvi/tYmrqU38X/jjs63aF/MJ0HlTSpHo4dgCVPwOq3PAXt8gehy03g73vnZ2blZ/H3NX/ng60fEBUSxf8l/h9XXXyVT/8gLCwuZNuRbWW3LDdmbGTHkR1lq1svCruI+Jh4TymLiaNddLsLtpyK+LqikiKeWP4EH23/iOHNh/PYJY8R6Od7c4PdQCVNqpf09Z791b5fBnXbeW6BNr/c6VQVkpyRzJPLn2TDoQ10rtuZh3o8RKvarZyOdVYltoTdWbvLblkmH0pmS+YWCkoKAKgVXOuUEbK4mDhiQmMcTi0i58Jay8vrX+afa//JpQ0v5fk+zxMWGOZ0LJ+jkibVj7WweS4seBiOfA+thnoOb49u7nSyc1ZiS5i1fRYvrH6B7IJsrm17LRMTJlIjqIbT0QDPD+r04+mn3LLclLGpbPVlaEAo7aLblRWy9jHtaVSjkU+PCorIjz7a9hGPL3+cNlFtmNZ/GtGhvnmUn1NU0qT6KsyD5f+Er/7qmbvW/fdw2b0Q6ns7/R/JO8LUNVP5aNtHxITGcE/iPQyNHVrlZScjN4PkjOSyUpackVx2gHyAXwCta7cuGx2Li44jNjJW55WKXOC+2PMF93xxD3XC6vDygJdpEtHE6Ug+QyVNJHs/LPkzrHnXswFuv4eh843gg+Vhw8ENPLHiCTZlbKJbvW482P1BmtfyzgjhsYJjbMrYdMpty7TjaQAYDBdHXvxjIYuJo1XtVto/SaSaWn9wPbcvvh0/48e0/tOIi4lzOpJPUEkTOSFtjWe+2g/fwkVxMOoVuKid06nOWXFJMR9t/4ipq6eSU5jDuHbjuDXh1vOaD5JfnM/WzK2n3LbcnbUbi+dnQMMaDctGx9rHtKdddDvCA8Mr61sSkQvA7qzd3LroVjLzMvlrn7/Su1FvpyO5nkqayMmshU0fw/w/QmEujJ4JLfo7napCMvMyeWHVC8xKmUXdsLrc1/U+BjUddNZboEUlRew4suOU25bbD2+nyBYBEB0SXTZ/7MRcstohvreliYhUvUO5h5i4aCLbDm/j0Z6PMrLlSKcjuZpKmsjpZKXCu7+Bg1vgquehy3inE1XY2gNreXLFk2zJ3EKP+j14sPuDxEbGAp6J/Xuy95SNjiUfSmZz5mZyi3IBqBFYg/bR7Wkf0574mHjiYuK4KOwiTewXkQo7XnicyZ9P5tv0b5nUcRITOkzQz5RfoJIm8kvyjsJ/boKURXDpH6D/Y+Dnm8cxFZcU8/7W9/nHmn+QW5zLlbFXcjD3IBsPbSw7QinYP5g2UW08o2TRnv3ImkY01RFUIlLpCosLeeSbR5i3cx5jWo/hgW4PaBHRaaikiZxJcRHMvxeSXod2I2DkdAgMdTpVhR3KPcTfVv2NT3d9Smxk7Cm3LVvUbqENJ0WkylhreWH1C7y+8XX6Ne7HM5c9o1NDfkIlTeRsrIVvp3n2VWvYBcb+G2rUcTrVebHW6vaCiLjCu5vf5ZmVz5BQJ4F/9P8HkcGRTkdyjfMpaboHItWDMXDJJBjzNuxPhlf7wYEtTqc6LypoIuIW17W9jil9ppCckcy4+eNIO5bmdKQLgkqaVC9th8FN//NsgvvaINi51OlEIiIXhEHNBjF94HQO5Rzi+k+uZ2vmVqcj+TyVNKl+GnaB3y2GiAbwzq9hzTtOJxIRuSB0rdeVN4e+iZ/xY/yn41mRvsLpSD5NJU2qp1pN4ObPoFlvmH07LH4cSkqcTiUi4vNa1m7JO1e8Q73wety66Fbm75rvdCSfpZIm1VdIJFz3IXS+Ab6aAv+9xXMbVEREzku98HrMHDKThDoJ3PflfbyZ/KbTkXySSppUb/6BMOxFGPAYbPwI3hoOxw85nUpExOdFBkcyfeB0BjYdyJSkKTz33XOUWN2xOBcqaSLGQK/JnuOj0tbCqwPg0HanU4mI+Lxg/2Ceu+w5xrYZy1ub3uL+L++noLjA6Vg+QyVN5IT2I2H8PMjP9hS13cucTiQi4vP8/fx5oNsDTO4ymfm753PbotvILsh2OpZPUEkTOVnjbnDLIqhRF976Faz7t9OJRER8njGG38b9lqd6PcXq/asZ/+l4DuQccDqW66mkifxUVCzcvACa9IBZv4fPn/acWCAiIudlWPNhTOs/jdTsVK7/5Hp2HtnpdCRXU0kTOZ3Q2nD9f6HjdfDFXzxlrSjf6VQiIj7vkoaX8MaQN8gvzmfc/HGsPbDW6UiupZIm8ksCgmDENOj3MKx/33P7MyfT6VQiIj6vXXQ73rniHWqH1OaWBbew+IfFTkdyJZU0kTMxBi67F379GuxN8iwoyNjhdCoREZ/XuGZj3hr6Fq1qt+LupXfzwdYPnI7kOippIuURfzXcMAdyD3uK2vffOp1IRMTnRYVE8eqgV+nVsBePL3+cv6/5O1ZzgMuopImUV9OenpWfobU9m95u+I/TiUREfF5YYBhTL5/KqJajmLF+Bo988wiFJYVOx3IFlTSRcxHd3FPUGnWFj26GL5/Tyk8RkfMU4BfAYz0f47aE2/g45WPuXHInOYU5TsdynEqayLkKi4Jxs6DDGFjyhOeA9iLtoC0icj6MMUzsOJFHej7CN2nfcPNnN5ORm+F0LEeppIlUREAwjJwOfe6Hte/CO6M889VEROS8jG41mhf6vkDKkRRumH8De47ucTqSY1TSRCrKGLj8AU9Z+2E5vDYIMnc5nUpExOdd3uRyXhn0ClkFWVw//3qSDyU7HckRKmki5yvhGrjhYzh2wLPyc893TicSEfF5Het25O2hbxPiH8JNn93Esr3V7zxllTSRytCsl2dBQXBNePMqSJ7ldCIREZ8XGxnLO1e8Q9OIptyx+A5mp8x2OlKVUkkTqSwxLeGWxVA/AT4cD8v+ppWfIiLnqU5YHd4Y/AZd6nXh4a8f5pX1r1SbvdRU0kQqU3i0Z9Pb9qNg0WMw904o1n4/IiLno0ZQDV7q/xJXxF7Bi2te5MkVT1JcUux0LK8LcDqAyAUnMMRzjFTUxfDVFDjyA/zmLQiJdDqZiIjPCvQP5OneT1M3rC4zk2eSkZvB072fJiQgxOloXqORNBFv8POD/n/yHNC+e5ln5efh751OJSLi0/yMH/+X+H/c1/U+Fv+wmN8v/D1Z+VlOx/IalTQRb+p0PVz/Xzia7ln5uXeV04lERHzeuHbjeLbPs2w4tIEb5t9A+rF0pyN5hfG1yXeJiYk2KSnJ6Rgi5+bgVnj3ajh2EH79CrQd5nQidyouhD0rYPsCOLTd6TQi1VPNejDwcQiu4XSSs/pu33fcueROwgLCeGngS7Sq3crpSD9jjFllrU2s0NeqpIlUkWMH4b1rPKNpgx6HnpM8G+JWd0fTIGWRp5jt/ALyj4JfAMS09tw2FpGqY4H9G6HLjTBsqtNpymXb4W3ctvA2copyeLHfi3St19XpSKdQSRPxFYW5MOv3sGk2JP4Whj4H/tVs/U5xIexZCSkLYfsi2L/B83zNBtByALQcBLF9ICTC2Zwi1dXCR+DrqTD2fWg9xOk05ZJ+LJ1bF93Knuw9PNXrKYbEuie3SpqILykpgcX/D75+AVoMgKvfuPALydF0z2hZykLYsRTys8D4Q5OePxazuu00sijiBkX58Ep/OLYPbvsWatRxOlG5ZOVncceSO1hzYA33db2Pce3GOR0JUEkT8U2rZsK8u6FOG7juA4hs5HSiylNcBKnfeW5hpiyEfSdGy+p7imnLgXBxX21LIuJW+zfBjL7Qoj9c8y+f+QdUXlEeD3z1AIt+WMT49uOZ3GUyfsbZaRMqaSK+ascS+OBGCAyDa9+HBh2dTlRx2ftPGi1bAnmlo2WNu3tKWcuBcFGcz/ywF6n2vp0Gnz0Iw/8OnW9wOk25FZcU8/TKp3l/6/tcEXsFT1z6BIH+gY7lUUkT8WX7N8G/fgM5GXD169B6qNOJyqe4CPYmwfaFnmKWvs7zfI2LoMXAH0fLQms5mVJEKqqkBN4eAamr4LZlng26fYS1ltc2vsbU1VPpXr87L/R9gRpBzqxWVUkT8XXZ+zwrP9PWwpC/QI9bnU50escOlK7EPDFadqR0tKzbj7cx63XQaJnIhSIrFV66xLPa+qb5PrfQaXbKbB795lFa1GrBSwNeok5Y1c+vU0kTuRAUHIf/ToAt86DbBBj8tPM/EEuKPVuGbF/omV+WvtbzfHhdTyFrMQCaXw6htZ3NKSLes+E/8NHN0O9huOxep9Ocs2V7l3H30rupHVyblwe+TGxkbJW+v0qayIWipNiz/P3bf0DLwZ7bn1W9oeSxg7Bjcelo2WLIPQzGDxp1LS1mpaNl2sNMpPr4z82w6WO4eSE07Ox0mnOWfCiZiYsnUmyL+Ue/f9CxbtXN/1VJE7nQfPcqfHIvXNQerv0AIhp4771KimHv6tJ9yxZC2hrAQnidk1ZiXg5hUd7LICLulnsYXrrUs8jp919CUJjTic7ZnqN7+P0iz1mfn/76U2oG1ayS91VJE7kQbV8IH46H4AjPFh314ivvtY9nlI6WLYCUxZCbCZgfR8taDoR6CRotE5Ef7VwKb43wTMe44jmn01RIRm4GWzO3cknDS6rsPVXSRC5U+zbAu7/xHJV09RvQalDFXqekxDNCllI6t2zvasBCWMyPo2XN+2m0TETO7NMHYfk0uP4jz88OOSuVNJEL2dE0+NcYz3l6Q5+Fbr8r39flZHpGyVIWelZk5mQABhp28ezw33IA1O+k0TIRKb/CPM8mt7mHYeK3+oddOZxPSfOttbQi1VFEA8/S949uhk/ugcxdngPa/fxPva6kxLP68sS+ZalJeEbLoqF5f08xa94PwqMd+TZE5AIQGAK/fgVmXA5z/wC/eUtb7niRSpqILwiu4Tma5bPSWw2Hd3t+UBble/YrO7ES8/hBPKNlnaHPHz23MRt0+nmhExGpqHrxnu04Fj0K6/4NHcc6neiCpZIm4iv8/GHoM1A7Fj57AKYmeG5h2hLPPmUtBni2x2jRH8JjnE4rIheyS+6AbZ95VqE3vQRqN3U60QVJJU3E1/S4FWo3g6TXPKNkLQZ6Rs40WiYiVcXPH0a+7NmWY9atMH6efgZ5gUqaiC9qPcTzS0TEKbWberbi+PhW+Obv0OsupxNdcLSsS0RERCom4RpoOxyWPAHp651Oc8FRSRMREZGKMQaGTfWsIv/vBM8WHVJpVNJERESk4sKi4FfT4OBmWPxnp9NcUFTSRERE5Py0GABdf+fZImjnUqfTXDC8WtKMMUOMMVuNMSnGmPt/4ZrfGGM2GWOSjTH/8mYeERER8ZKBf4aYVjDrNs+JBHLevFbSjDH+wDRgKNAOGGuMafeTa1oCDwCXWmvbA1oaIiIi4ouCwmDUDDh+AP53j9NpLgjeHEnrBqRYa3daawuAfwMjfnLN74Bp1trDANbaA17MIyIiIt7UoBP0vR82/gc2/MfpND7PmyWtIbDnpMeppc+drBXQyhjztTFmuTFGGz+JiIj4sksnQ6NuMO9uyEp1Oo1P82ZJO92Jq/YnjwOAlkBfYCzwqjGm1s9eyJgJxpgkY0zSwYMHKz2oiIiIVBL/ABg1HWwxfHwblJQ4nchnebOkpQKNT3rcCEg7zTWzrbWF1tpdwFY8pe0U1toZ1tpEa21inTp1vBZYREREKkHUxTDkadj1Jax4yek0PsubJe07oKUxJtYYEwRcA8z5yTUfA5cDGGNi8Nz+3OnFTCIiIlIVOo2D1lfAov8H+zc5ncYnea2kWWuLgEnAZ8Bm4ANrbbIx5s/GmOGll30GZBhjNgGfA/daazO8lUlERESqiDEw7EUIiYD//g6K8p1O5HOMtT+dJuZuiYmJNikpyekYIiIiUh5bP4X3xsClf/DspVbNGGNWWWsTK/K1OnFAREREvKf1EOgyHr5+EXYvczqNT1FJExEREe8a9CRExcKsWyEvy+k0PkMlTURERLwruAaMegWOpsH8PzqdxmeopImIiIj3NUqEy+6Bde9B8sdOp/EJKmkiIiJSNS67Fxp0hnl3wdF0p9O4nkqaiIiIVA3/QM9tz6J8mD0RfGyHiaqmkiYiIiJVJ6YFDHoCdiyBla84ncbVVNJERESkaiX+FloOgoV/goNbnU7jWippIiIiUrWMgeH/gKDw0tMICpxO5EoqaSIiIlL1al4Ew6ZC+jr44hmn07iSSpqIiIg4o+0w6Hg9LHsefljhdBrXUUkTERER5wz9C0Q2hlkTID/b6TSuopImIiIizgmuCaNmwJEf4NMHnE7jKippIiIi4qwmPeDSu2DN27B5ntNpXEMlTURERJzX9wGonwBz74Ts/U6ncQWVNBEREXFeQBCMnAEFx2HOHTqNAJU0ERERcYu6bWDA/4Ptn8GqN5xO4ziVNBEREXGPbhPg4svhs4fgUIrTaRylkiYiIiLu4ecHv/on+Ad5tuUoLnI6kWNU0kRERMRdIhrAVX+DvavgqylOp3GMSpqIiIi4T9wo6DAGvngWUpOcTuMIlTQRERFxpyue84yq/XeCZ9VnNaOSJiIiIu4UEgkjX4bMnbDgYafTVDmVNBEREXGvZr3gkkmQ9Dps+8zpNFVKJU1ERETcrd+f4KI4mD0Jjh9yOk2VUUkTERERdwsI9hzCnncE5v6h2pxGoJImIiIi7ndRe+j/CGyZB2vecTpNlVBJExEREd/Q43Zo1hs+vR8ydzmdxutU0kRERMQ3+PnBr14C4w+zfg8lxU4n8iqVNBEREfEdtRrDlVNgzwpY9jen03iVSpqIiIj4lvjR0H4ULH0a0tY4ncZrVNJERETEtxgDV/4Vwut6TiMozHU6kVeopImIiIjvCYuCX/0TDm2DhY86ncYrVNJERETENzW/HLrfBiunQ8pip9NUOpU0ERER8V0DHoU6beDjiZCT6XSaSqWSJiIiIr4rMNRzGkFOBsybfEGdRqCSJiIiIr6tfgJc/iBs+hjWv+90mkpT7pJmjOlljLmp9OM6xphY78USEREROQeX/gGaXAKf3AtHfnA6TaUoV0kzxjwK/BF4oPSpQKB6HJwlIiIi7ufnDyNf9tzunHXbBXEaQXlH0kYCw4HjANbaNKCmt0KJiIiInLPaTWHoM/D9Mvj2H06nOW/lLWkF1loLWABjTLj3IomIiIhUUMdroe0wWPw47NvgdJrzUt6S9oExZjpQyxjzO2AR8Ir3YomIiIhUgDFw1VTPZrf/nQCFeU4nqrBylTRr7RTgP8BHQGvgEWvt370ZTERERKRCwqNhxDQ4sAmWPO50mgoLONsFxhh/4DNr7QBgofcjiYiIiJynlgOh6y2euWktB8HFfZxOdM7OOpJmrS0GcowxkVWQR0RERKRyDHwcolvAx7dB7hGn05yz8s5JywM2GGNeM8a8eOKXN4OJiIiInJegMM9pBMf2wyf3OJ3mnJ31dmep/5X+EhEREfEdDbtAnz/C509CqyEQf7XTicqtXCXNWvumMSYIaFX61FZrbaH3YomIiIhUkl53w/YF8L+7oUlPiGzodKJyKe+JA32B7cA04J/ANmPMZV7MJSIiIlI5/ANg5HQoLvLMTyspcTpRuZR3TtpfgUHW2j7W2suAwcDfvBdLREREpBJFN4chT0FwTSjMcTpNuZR3TlqgtXbriQfW2m3GmEAvZRIRERGpfJ1v9Pwyxukk5VLekpZkjHkNeLv08XXAKu9EEhEREfECHylnJ5S3pN0G3A7cCRjgSzxz00RERETEC8pb0gKAqdba56HsFIJgr6USERERqebKu3BgMRB60uNQPIesi4iIiIgXlLekhVhrj514UPpxmHciiYiIiEh5S9pxY0znEw+MMYlArnciiYiIiEh556TdBXxojEkDLNAAGOO1VCIiIiLV3BlH0owxXY0x9ay13wFtgPeBIuBTYFcV5BMRERGpls52u3M6UFD6cU/gQTxHQx0GZngxl4iIiEi1drbbnf7W2szSj8cAM6y1HwEfGWPWejeaiIiISPV1tpE0f2PMiSLXH1hy0ufKO59NRERERM7R2YrWe8AXxphDeFZzfgVgjGkBZHk5m4iIiEi1dcaSZq190hizGKgPLLDW2tJP+QF3eDuciIiISHV11luW1trlp3lum3fiiIiIiAiUfzNbEREREalCKmkiIiIiLqSSJiIiIuJCKmkiIiIiLqSSJiIiIuJCKmkiIiIiLqSSJiIiIuJCKmkiIiIiLqSSJiIiIuJCKmkiIiIiLqSSJiIiIuJCKmkiIiIiLqSSJiIiIuJCKmkiIiIiLqSSJiIiIuJCKmkiIiIiLqSSJiIiIuJCKmkiIiIiLqSSJiIiIuJCKmkiIiIiLqSSJiIiIuJCKmkiIiIiLqSSJiIiIuJCKmkiIiIiLqSSJiIiIuJCKmkiIiIiLqSSJiIiIuJCKmkiIiIiLqSSJiIiIuJCKmkiIiIiLqSSJiIiIuJCKmkiIiIiLqSSJiIiIuJCKmkiIiIiLuTVkmaMGWKM2WqMSTHG3H+G6642xlhjTKI384iIiIj4Cq+VNGOMPzANGAq0A8YaY9qd5rqawJ3ACm9lEREREfE13hxJ6wakWGt3WmsLgH8DI05z3ePAs0CeF7OIiIiI+BRvlrSGwJ6THqeWPlfGGNMJaGytnefFHCIiIiI+x5slzZzmOVv2SWP8gL8B/3fWFzJmgjEmyRiTdPDgwUqMKCIiIuJO3ixpqUDjkx43AtJOelwTiAOWGmN2Az2AOadbPGCtnWGtTbTWJtapU8eLkUVERETcwZsl7TugpTEm1hgTBFwDzDnxSWttlrU2xlrbzFrbDFgODLfWJnkxk4iIiIhP8FpJs9YWAZOAz4DNwAfW2mRjzJ+NMcO99b4iIiIiF4IAb764tfYT4JOfPPfIL1zb15tZRERERHyJThwQERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBEREREXUkkTERERcSGVNBERkf/f3r0H21rXdRz/fAW1aUBpBB0HRZzCC6J5OZKgeRkZbzWQig2OVhjJNI2Sms7QWIpak2lkOqKCRqSTF7xkpDjYKKZyUUwUBXMiYpTQIS+hZmLgtz/Wc2S12WfvdQ5n7fNb+XrN7Dnr8qzn+e39m7158zzPWg8MSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADEikAQAMSKQBAAxIpAEADGipkVZVT6iqL1fVlVV18jrPv6Cqrqiqy6rqI1V1j2WOBwBgVSwt0qpqrySnJXlikkOTPL2qDl2z2KVJtnX3A5K8J8mrljUeAIBVssw9aYcnubK7r+ruHyZ5Z5Jj5hfo7vO7+/vT3YuT3G2J4wEAWBnLjLQDk3x17v4102M7ckKSDy1xPAAAK2PvJa671nms112w6plJtiV51A6ePzHJiUly0EEH7a7xAQAMa5l70q5Jcve5+3dLcu3aharqqO1WajIAAAv4SURBVCQvTnJ0d9+w3oq6+4zu3tbd2w444IClDBYAYCTLjLRLkhxSVfesqtslOS7JOfMLVNWDkpyeWaBdt8SxAACslKVFWnffmOQ5Sc5L8qUkZ3f35VX18qo6elrs1Un2SfLuqvpcVZ2zg9UBAPxEWeY5aenuc5Ocu+axl8zdPmqZ2wcAWFWuOAAAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMKClRlpVPaGqvlxVV1bVyes8f/uqetf0/Keq6uBljgcAYFUsLdKqaq8kpyV5YpJDkzy9qg5ds9gJSb7d3T+X5DVJ/nRZ4wEAWCXL3JN2eJIru/uq7v5hkncmOWbNMsck+evp9nuSPLaqaoljAgBYCcuMtAOTfHXu/jXTY+su0903Jrk+yZ2WOCYAgJWw9xLXvd4esd6FZVJVJyY5cbp7Q1V98VaOjT1n/yTf2NODYJeYu9Vm/laXuVtt997VFy4z0q5Jcve5+3dLcu0OlrmmqvZOcsck31q7ou4+I8kZSVJVn+nubUsZMUtn/laXuVtt5m91mbvVVlWf2dXXLvNw5yVJDqmqe1bV7ZIcl+ScNcuck+Q3ptvHJvlod99iTxoAwE+ape1J6+4bq+o5Sc5LsleSM7v78qp6eZLPdPc5Sf4yyduq6srM9qAdt6zxAACskmUe7kx3n5vk3DWPvWTu9g+SPG0nV3vGbhgae475W13mbrWZv9Vl7lbbLs9fOboIADAel4UCABjQsJHmklKra4G5e0FVXVFVl1XVR6rqHntinKxvs/mbW+7Yquqq8q6zgSwyf1X1q9Pv4OVV9fatHiPrW+Bv50FVdX5VXTr9/XzSnhgnt1RVZ1bVdTv6iLCaed00t5dV1YMXWe+QkeaSUqtrwbm7NMm27n5AZleaeNXWjpIdWXD+UlX7Jjkpyae2doRsZJH5q6pDkvx+kod39/2SPG/LB8otLPi79wdJzu7uB2X2Rrs3bO0o2cBZSZ6wwfNPTHLI9HVikjcustIhIy0uKbXKNp277j6/u78/3b04s8/QYwyL/O4lySsyi+sfbOXg2NQi8/fsJKd197eTpLuv2+Ixsr5F5q6T3GG6fcfc8rNH2UO6++NZ53Ne5xyT5K09c3GS/arqrputd9RIc0mp1bXI3M07IcmHljoidsam81dVD0py9+7+wFYOjIUs8vt3ryT3qqoLquriqtro//7ZOovM3SlJnllV12T2yQnP3ZqhsRvs7H8bkyz5Izhuhd12SSm23MLzUlXPTLItyaOWOiJ2xobzV1W3yez0guO3akDslEV+//bO7JDLozPbi/2Jqjqsu/9zyWNjY4vM3dOTnNXdp1bVEZl9zuhh3f2j5Q+PW2mXmmXUPWk7c0mpbHRJKbbcInOXqjoqyYuTHN3dN2zR2NjcZvO3b5LDknysqq5O8rAk53jzwDAW/dv5d939P939b0m+nFm0sWctMncnJDk7Sbr7oiQ/ldl1PRnfQv9tXGvUSHNJqdW16dxNh8tOzyzQnA8zlg3nr7uv7+79u/vg7j44s3MKj+7uXb42HbvVIn8735/kMUlSVftndvjzqi0dJetZZO6+kuSxSVJV980s0v5jS0fJrjonya9P7/J8WJLru/trm71oyMOdLim1uhacu1cn2SfJu6f3enylu4/eY4PmxxacPwa14Pydl+RxVXVFkpuSvKi7v7nnRk2y8Nz9XpI3V9XzMztUdrydE2OoqndkdgrB/tM5gy9Nctsk6e43ZXYO4ZOSXJnk+0metdB6zS8AwHhGPdwJAPATTaQBAAxIpAEADEikAQAMSKQBAAxIpAGbqqquqlPn7r+wqk7ZTes+par+vao+N329cnesd53tnFVVx26yzPFV9fpdXP9+VfU7O3juNVX1vLn751XVW+bun1pVL9hk/RcuMIarp88+W/v4o6vqyM1eD4xFpAGLuCHJU9YLgN3kNd39wOnr5LVPVtVeS9ru7rRfknUjLcmFSY5Mfnxprf2T3G/u+SOTXLDRyrv71kTWo7dvH1gdIg1YxI1Jzkjy/LVPVNU9quojVXXZ9O9B0+NnVdXrqurCqrpqs71Y66z36qp6SVV9MsnTqurZVXVJVX2+qt5bVT89t51j5173venfqqrXV9UVVfXBJHdes+79p9vbqupj62z/gGk7l0xfD58eP6Wqzqyqj03f10nTS16Z5GenvYGvXrO6C3JzJN0vyReTfLeqfqaqbp/kvkkundb/oml7l1XVy9b5vm5TVW+oqsur6gNVde6an+1zq+qzVfWFqrpPVR2c5LeTPH8a2y8uPAnAHiXSgEWdluQZVXXHNY+/Pslbu/sBSf4myevmnrtrkkck+eXMImZHtgfE56rq8XOP/6C7H9Hd70zyvu5+aHf/fJIvZXYdw408Ocm9k9w/ybOz83uSXpvZHr6HJnlqkrfMPXefJI9PcniSl1bVbZOcnORfp72BL5pfUXdfm+TGKWCPTHJRkk8lOSLJtiSXdfcPq+pxmV1H8/AkD0zykKp65JpxPSXJwdP39VvTOuZ9o7sfnOSNSV7Y3VcneVNu3lv5iZ38OQB7yJCXhQLG093fqaq3JjkpyX/PPXVEZuGQJG9L8qq5597f3T9KckVV3WWD1b+mu/9sncffNXf7sKr6o8wOK+6T2eVzNvLIJO/o7puSXFtVH91k+bWOSnLodOmyJLlDVe073f5gd9+Q5Iaqui7JRt/bdtv3ph2Z5M+THDjdvj6zw6FJ8rjp69Lp/j6ZRdvH59bziCTvnn6uX6+q89ds533Tv/+Um+cFWEEiDdgZf5Hks0n+aoNl5q81d8Pc7UqSqvrjJL+UJN39wE22919zt89K8ivd/fmqOj6z86yS2aHY20zrriS328FY5v34NZldpHo9t0lyRHfPB2mmaJv/vm7KYn9Lt5+Xdv/MDnd+NbNrMX4nyZnbV5/kT7r79A3WUxs8Nz+2RccFDMrhTmBh3f2tJGfn/x5qvDDJcdPtZyT55CbrePH2Nwns5Ob3TfK16dDiM+YevzrJQ6bbx2S6qHFme5+Oq6q9ququSR6zg9c8dQfb+3CS52y/U1Wbjfe70xh35ILMDvt+q7tvmn6W+2W2J/KiaZnzkvxmVe0zbfPAqrrzmvV8MslTp3PT7pKbY/XWjA0YkEgDdtapmb07cbuTkjyrqi5L8mtJfndJ2/3DzM7j+ock/zz3+JuTPKqqPp3kF3Lz3re/TfIvSb6Q2flZ/zj3mpcleW1VfSKzPU7rOSnJtukE/isyO/l+h7r7m0kuqKovrvPGgUzj2D/JxWseu767vzGt48NJ3p7koqr6QpL35JZx9d4k12S2N+70zH4m1280tiR/n+TJ3jgAq6W6d3Q0AIARVdU+3f29qrpTkk8neXh3f31PjwvYvZyvALB6PlBV+2V2/t0rBBr8/2RPGgDAgJyTBgAwIJEGADAgkQYAMCCRBgAwIJEGADAgkQYAMKD/BRuQzImoxvuwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f925d4b160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Plot all three scores on the same graph\n",
    "plt.plot(weights, precision_scores, label='Precision Score')\n",
    "plt.plot(weights, recall_scores, label='Recall Score')\n",
    "plt.plot(weights, f1_scores, label='F1 Score')\n",
    "\n",
    "# Make it look nice\n",
    "plt.xlabel('Non-Fraudulent Weight')\n",
    "plt.ylabel('Score')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that when the non-fraudulent class is weighted lower (and the fraudulent class weighted higher) that all three metrics are improved and seem to level out as the weight approaches zero. Let's see if a different classifier can get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for k=1: \n",
      " (0.7741935483870968, 0.7058823529411765, 0.7384615384615385, None)\n",
      "Result for k=2: \n",
      " (0.8846153846153846, 0.6764705882352942, 0.7666666666666666, None)\n",
      "Result for k=3: \n",
      " (0.8620689655172413, 0.7352941176470589, 0.7936507936507937, None)\n",
      "Result for k=4: \n",
      " (0.8888888888888888, 0.7058823529411765, 0.7868852459016393, None)\n",
      "Result for k=5: \n",
      " (0.8571428571428571, 0.7058823529411765, 0.7741935483870968, None)\n",
      "Result for k=6: \n",
      " (0.8571428571428571, 0.7058823529411765, 0.7741935483870968, None)\n",
      "Result for k=7: \n",
      " (0.8571428571428571, 0.7058823529411765, 0.7741935483870968, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "precision_knn = []\n",
    "recall_knn = []\n",
    "f1_knn = []\n",
    "n_neighbors_range = 9\n",
    "for i in np.arange(1, n_neighbors_range):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i, n_jobs=3)\n",
    "    knn.fit(X_train.iloc[:n_subset_examples, :], y_train.iloc[:n_subset_examples])\n",
    "    y_pred_knn = knn.predict(X_test.iloc[:n_subset_examples, :])\n",
    "    result = precision_recall_fscore_support(y_test.iloc[:n_subset_examples], y_pred_knn, average='binary')\n",
    "    precision_knn.append(result[0])\n",
    "    recall_knn.append(result[1])\n",
    "    f1_knn.append(result[2])\n",
    "    print('Result for k={}: \\n'.format(i), result)\n",
    "n_neighbors = np.arange(1, n_neighbors_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(n_neighbors, recall_knn, label='Recall')\n",
    "plt.plot(n_neighbors, precision_knn, label='Precision')\n",
    "plt.plot(n_neighbors, f1_knn, label='F1')\n",
    "plt.legend()\n",
    "plt.xlim([0, 10])\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, I would still like to get a higher recall score. Let's try another SVC but this time we will use a non-linear kernel. Failing high recall with that, we will try an ensemble method like random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# We will use a class weight of 0.15, because that seemed to work well in our LinearSVC\n",
    "rbf_clf = SVC(class_weight={0:0.15, 1:0.85}, kernel='rbf')\n",
    "rbf_clf.fit(X_train, y_train)\n",
    "y_pred_rbf = rbf_clf.predict(X_test)\n",
    "result = precision_recall_fscore_support(y_test, y_pred_rbf, average='binary')\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
